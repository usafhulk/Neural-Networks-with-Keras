{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CiHWAuO59Vlp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Use tensorflow.keras instead of just keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "import matplotlib as plt\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "start by defining the sentences and text for translation training Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs. Target Sequences: Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.:"
      ],
      "metadata": {
        "id": "TSU4bGXI-36e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample parallel sentences (English -> Spanish)\n",
        "input_texts = [\n",
        "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
        "]\n",
        "target_texts = [\n",
        "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
        "]\n",
        "\n",
        "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
      ],
      "metadata": {
        "id": "PX1ishyS9YHN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- convert the text from the sentences to tokens and create a vocabulary\n",
        "- Tokenization: Uses Tokenizer to convert words into numerical sequ144ences"
      ],
      "metadata": {
        "id": "FxvHFgQP-4PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "input_tokenizer = Tokenizer()\n",
        "input_tokenizer.fit_on_texts(input_texts)\n",
        "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
        "\n",
        "output_tokenizer = Tokenizer()\n",
        "output_tokenizer.fit_on_texts(target_texts)\n",
        "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "output_vocab_size = len(output_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "ygMGGAUD-4v0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding: Ensures all sequences have the same length."
      ],
      "metadata": {
        "id": "5qRkHNSd_MhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "max_input_length = max([len(seq) for seq in input_sequences])\n",
        "max_output_length = max([len(seq) for seq in output_sequences])\n",
        "\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
        "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
      ],
      "metadata": {
        "id": "yn41hBkk-_wz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the target data for training\n",
        "decoder_input_data = output_sequences[:, :-1]\n",
        "decoder_output_data = output_sequences[:, 1:]\n",
        "\n",
        "# Convert to one-hot\n",
        "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
      ],
      "metadata": {
        "id": "IyXMQAfT_I4c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
        "- Machine Translation (e.g., aligning words correctly)\n",
        "- Text Summarization\n",
        "- Speech Recognition\n",
        "- Image Processing (Vision Transformers)\n",
        "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
        "\n",
        "\n",
        "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
        "\n",
        "- Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
        "For each word (token) in a sequence:\n",
        "\n",
        "Query (Q): What this word is looking for.\n",
        "Key (K): What this word represents.\n",
        "Value (V): The actual information in the word.\n",
        "\n",
        "- Compute **Attention Scores**\n",
        "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
        "Each word in a sequence attends to every other word based on these scores.\n",
        "\n",
        "- Apply **Scaling & Softmax**\n",
        "Since dot-product values can be large, we scale them.\n",
        "Next, Applying softmax converts scores into attention weights:\n"
      ],
      "metadata": {
        "id": "qh97y5R6_W2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this implementation of self-attention layer:\n",
        "\n",
        "### We first initialize the weights in the build method, where:<BR/>\n",
        "A) self.Wq, self.Wk, self.Wv are the trainable weight matrices.<BR/>\n",
        "B) Their shape is (feature_dim, feature_dim), meaning they transform input features into Q, K, and V representations.<BR/>\n",
        "### Applying Attention using call method. The call() method:<BR/>\n",
        "A) computes Q, K, V by multiplying inputs (encoder/decoder output) with their respective weight matrices.<BR/>\n",
        "B) Computes dot-product attention scores using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.<BR/>\n",
        "C) Scales the scores to avoid large values.<BR/>\n",
        "D) Applies softmax to normalize the attention scores.<BR/>\n",
        "### Multiplies attention weights with V to get the final output.<BR/>\n",
        "A) The compute_output_shape method defines the shape of the output tensor after the layer processes an input.<BR/>\n",
        "B) The output shape of the Self-Attention layer remains the same as the input shape.<BR/>\n",
        "C) The attention mechanism transforms the input but does not change its dimensions.4\n",
        "If the attention layer changed the shape, you would modify compute_output_shape"
      ],
      "metadata": {
        "id": "ll-uqs6kBRi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Self-Attention Layer\n",
        "class SelfAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SelfAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        feature_dim = input_shape[-1]\n",
        "        # Weight matrices for Q, K, V\n",
        "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True,\n",
        "                                  name='Wq')\n",
        "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True,\n",
        "                                  name='Wk')\n",
        "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True,\n",
        "                                  name='Wv')\n",
        "        super(SelfAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Linear projections\n",
        "        q = K.dot(inputs, self.Wq)  # Query\n",
        "        k = K.dot(inputs, self.Wk)  # Key\n",
        "        v = K.dot(inputs, self.Wv)  # Value\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
        "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
        "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
        "\n",
        "        # Weighted sum of values\n",
        "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape"
      ],
      "metadata": {
        "id": "FS_hjACI_XTF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z9610OkYCLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The model follows an Encoder-Decoder structure:\n",
        "\n",
        "### Encoder:\n",
        "1) Takes input sentences (padded and tokenized).<BR/>\n",
        "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).<BR/>\n",
        "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.<BR/>\n",
        "4) Outputs context vectors (hidden & cell states).\n",
        "\n",
        "### Attention Layer\n",
        "1) Applied to both the encoder and decoder outputs.<BR/>\n",
        "2) Helps the decoder focus on relevant words during translation.<BR/>\n",
        "\n",
        "### Decoder\n",
        "1) Receives target sequences (shifted one step ahead).<BR/>\n",
        "2) Uses an LSTM with encoder states as initial states.<BR/>\n",
        "3) Applies self-attention for better learning.<BR/>\n",
        "4) Uses a Dense layer (Softmax) to predict the next word.\n"
      ],
      "metadata": {
        "id": "82l4o9RGCi6_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KiMIAfLCCjYa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}